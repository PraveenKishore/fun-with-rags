{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "In this notebook, we will:\n",
    "- Introduce LLMs and the concept of Retrieval-Augmented Generation (RAG)\n",
    "- Build a playful chatbot example (with a pirate twist) that demonstrates memory and context handling\n",
    "- Dive into embedding techniques, vector stores, and visualize embeddings with UMAP and Plotly\n",
    "- Implement a simple RAG pipeline using a PDF document as the knowledge source\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Intro](./data/slides/slide1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![What are we building?](./data/slides/slide2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Journey?](./data/slides/slide3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![What are LLMs?](./data/slides/slide4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_huggingface.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "from fastembed import TextEmbedding\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "import chromadb\n",
    "import chromadb.utils.embedding_functions as chroma_embedding_functions\n",
    "import umap.umap_ as umap\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import plotly.graph_objects as go\n",
    "import getpass\n",
    "import os\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "OLLAMA_HOST = 'http://localhost:5050'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model\n",
    "\n",
    "# model = ChatOllama(\n",
    "#   model=\"llama3.1:8b-instruct-q4_0\",\n",
    "#   temperature=0,\n",
    "#   seed=42,\n",
    "# )\n",
    "\n",
    "# openai_api_key = getpass.getpass(\"Enter your OpenAI API key: \")\n",
    "openai_api_key = os.environ['OPENAI_API_KEY']\n",
    "model = ChatOpenAI(\n",
    "  model=\"gpt-4o-mini\",\n",
    "  temperature=0,\n",
    "  seed=42,\n",
    "  api_key=openai_api_key\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's build a simple pirate chatbot\n",
    "\n",
    "*Notice how we keep the instructions concise to ensure clear behavior.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(\n",
    "  template=\"\"\"\n",
    "  You are a pirate, you must answer all questions with pirate speak. Also, keep your responses short and to the point.\n",
    "  Question: {question}\n",
    "  Answer:\n",
    "  \"\"\",\n",
    "  input_variables=[\"question\"],\n",
    ")\n",
    "\n",
    "model_chain = prompt | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Arrr, I be feelin' as fine as a treasure chest full o' gold!\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's test the chain\n",
    "model_chain.invoke({\"question\": \"How are you?\"}).content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <del>*\"You always forget!\"*</del> \n",
    "### Let's add some memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ye be called Bob, matey!'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke([\n",
    "  SystemMessage(content=\"You are a pirate, you must answer all questions with pirate speak. Also, keep your responses short and to the point.\"),\n",
    "  HumanMessage(content=\"Hi! I'm Bob\"),\n",
    "  AIMessage(content=\"Hello Bob! How can I assist you today?\"),\n",
    "  HumanMessage(content=\"What's my name?\"),\n",
    "]).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = [\n",
    "  SystemMessage(content=\"You are a pirate, you must answer all questions with pirate speak. Also, keep your responses short and to the point.\"),\n",
    "]\n",
    "max_qs = 10 # limit memory to a maximum number of messages to avoid overloading the context window.\n",
    "\n",
    "def chat(message):\n",
    "  global memory\n",
    "\n",
    "  # trim old questions\n",
    "  if len(memory) > max_qs:\n",
    "    memory = memory[0:1] + memory[-max_qs:]\n",
    "  \n",
    "  memory.append(HumanMessage(content=message))\n",
    "  response = model_chain.invoke(memory)\n",
    "  memory.append(response)\n",
    "  return response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Ahoy, Bob! What be yer treasure seekin' today?\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's try the memory enabled chat\n",
    "chat('I am Bob')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Ye be Bob, a brave soul sailin' the seas! Arrr!\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat('Who am I?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Context Lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(\n",
    "  template=\"\"\"\n",
    "  You are an AI book assistant, you will answer any question about the book I'm providing.\n",
    "  You must answer the questions that are from the given book only, if you don't know the answer, \n",
    "  then just say that you don't know. Also, mention the list of references from the book that you used to answer the question in the references section.\n",
    "  Answer in the given json format.\n",
    "  Book: \n",
    "  {book}\n",
    "  ---\n",
    "  Question: {question}\n",
    "  open brace\n",
    "    \"answer\": \"<your answer here>\",\n",
    "    \"references\": [list of reference paragraphs]\n",
    "  close brace\n",
    "  \"\"\",\n",
    "  input_variables=[\"book\", \"question\"],\n",
    ")\n",
    "\n",
    "model_chain = prompt | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of chars in the book: 15586\n"
     ]
    }
   ],
   "source": [
    "with open('./data/docs/a-very-old-man-with-enormous-wings.txt') as f:\n",
    "  book_text = f.read()\n",
    "\n",
    "print(f'No. of chars in the book: {len(book_text)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "  \"answer\": \"A Very Old Man with Enormous Wings tells the story of a decrepit angel who becomes a spectacle for a curious town, revealing the absurdity of human nature and the fleeting nature of wonder.\",\n",
      "  \"references\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "response = model_chain.invoke({\n",
    "  'book': book_text,\n",
    "  'question': 'Summarize the book for me in 1 line'\n",
    "})\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%html\n",
    "<iframe src=\"https://gpt-tokenizer.dev/\" height=\"600\" width=\"1000\"></iframe>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Context lengths of models as of Dec 2024:\n",
    "\n",
    "| **Model**                   | **Context Length** |\n",
    "|-----------------------------|--------------------|\n",
    "| Gemma 2b                    | 8k tokens          |\n",
    "| Gemma 7b                    | 8k tokens          |\n",
    "| GPT-3.5 (Turbo)             | 16k tokens         |\n",
    "| Gemini 1.0                  | 32k tokens         |\n",
    "| GPT-4o/mini                 | 128k tokens        |\n",
    "| Llama 3.1 (all)             | 128k tokens        |\n",
    "| Claude 3                    | 200k tokens        |\n",
    "| Gemini 1.5 Pro              | 2m tokens          |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enter RAG!\n",
    "\n",
    "RAG (Retrieval-Augmented Generation) is an AI framework that combines the strengths of traditional information retrieval systems (such as search and databases) with the capabilities of generative large language models (LLMs)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./data/slides/rag-architecture.png\" width=\"1000\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = [\n",
    "  \"The cat sat on the mat.\",\n",
    "  \"A dog is playing in the yard.\",\n",
    "  \"A bird is singing in the tree.\",\n",
    "  \"The horse is galloping in the field.\",\n",
    "  \"The chair is next to the table.\",\n",
    "  \"The book is on the shelf.\",\n",
    "  \"The computer is on the desk.\",\n",
    "  \"Mars is known as the Red Planet.\",\n",
    "  \"Jupiter is the largest planet in our solar system.\",\n",
    "  \"Saturn has beautiful rings.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_fun = chroma_embedding_functions.DefaultEmbeddingFunction() # all-MiniLM-L6-v2\n",
    "# emb_fun(['The cat sat on the mat'])[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = chromadb.Client()\n",
    "\n",
    "# Clean up any existing collection for a fresh start\n",
    "existing = [collection.name for collection in client.list_collections()]\n",
    "if \"rag\" in existing:\n",
    "  client.delete_collection(\"rag\")\n",
    "\n",
    "collection = client.create_collection(\n",
    "  \"rag\", \n",
    "  embedding_function=emb_fun,\n",
    ")\n",
    "\n",
    "collection.add(\n",
    "  documents=docs,\n",
    "  ids=[str(i) for i in range(len(docs))],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['A dog is playing in the yard.', 'The horse is galloping in the field.']]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Querying the collection\n",
    "results = collection.query(\n",
    "  query_texts=[\"animals\"],\n",
    "  n_results=2\n",
    ")\n",
    "results['documents']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_embeds(dataset, query = (None, None), retreived=(None, None)): # all params are tuples of (projected_embeds, docs)\n",
    "  projected_dataset_embeds, dataset_docs = dataset\n",
    "  projected_query_embeds, query_doc = query\n",
    "  projected_retreived_embeds, retreived_docs = retreived\n",
    "  \n",
    "  fig = go.Figure()\n",
    "  fig.add_trace(\n",
    "    go.Scatter(\n",
    "      x=projected_dataset_embeds[:, 0], y=projected_dataset_embeds[:, 1],\n",
    "      name='Dataset', mode='markers', text=dataset_docs, hoverinfo='text', \n",
    "      marker=dict(size=10, color='gray'),\n",
    "    ),\n",
    "  )\n",
    "  if retreived_docs:\n",
    "    fig.add_trace(\n",
    "      go.Scatter(\n",
    "        x=projected_retreived_embeds[:, 0], y=projected_retreived_embeds[:, 1],\n",
    "        name='Retrieved', mode='markers', text=retreived_docs, hoverinfo='text', \n",
    "        marker=dict(size=10, color='green'),\n",
    "      )\n",
    "    )\n",
    "  if query_doc:\n",
    "    fig.add_trace(\n",
    "      go.Scatter(\n",
    "        x=projected_query_embeds[:, 0], y=projected_query_embeds[:, 1],\n",
    "        name='Query', mode='markers', text=[query_doc], hoverinfo='text', \n",
    "        marker=dict(size=10, color='red', symbol='diamond'),\n",
    "      )\n",
    "    )\n",
    "  fig.update_layout(\n",
    "      title=f'Query: {query_doc}' if query_doc else 'Dataset Projection', showlegend=True,\n",
    "      xaxis=dict(scaleanchor=\"y\", scaleratio=1, visible=False),\n",
    "      yaxis=dict(scaleanchor=\"x\", scaleratio=1, visible=False),\n",
    "  )\n",
    "  fig.show()\n",
    "\n",
    "def project_embeds(embeddings, umap_transform):\n",
    "  projected_embeds = np.empty((len(embeddings), 2))\n",
    "  for i, embed in enumerate(tqdm(embeddings)):\n",
    "    projected_embeds[i] = umap_transform.transform([embed])\n",
    "  return projected_embeds\n",
    "\n",
    "def get_projection_transform(dataset_embeds):\n",
    "  return umap.UMAP(random_state=42, transform_seed=42, n_jobs=1, n_neighbors=dataset_embeds.shape[0]-1).fit(dataset_embeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get dataset embeddings from collection\n",
    "results = collection.get(include=['embeddings', 'documents'])\n",
    "dataset_embeds, dataset_docs = results['embeddings'], results['documents']\n",
    "projection_transoform = get_projection_transform(dataset_embeds)\n",
    "\n",
    "# Project the embeddings\n",
    "projected_dataset_embeds = project_embeds(dataset_embeds, projection_transoform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hoverinfo": "text",
         "marker": {
          "color": "gray",
          "size": 10
         },
         "mode": "markers",
         "name": "Dataset",
         "text": [
          "The cat sat on the mat.",
          "A dog is playing in the yard.",
          "A bird is singing in the tree.",
          "The horse is galloping in the field.",
          "The chair is next to the table.",
          "The book is on the shelf.",
          "The computer is on the desk.",
          "Mars is known as the Red Planet.",
          "Jupiter is the largest planet in our solar system.",
          "Saturn has beautiful rings."
         ],
         "type": "scatter",
         "x": [
          -0.7248413562774658,
          -0.621078372001648,
          -0.6760779619216919,
          3.3746416568756104,
          3.479097366333008,
          1.7489396333694458,
          2.774500846862793,
          3.26139497756958,
          2.7803049087524414,
          0.455700159072876
         ],
         "y": [
          19.685911178588867,
          19.28030776977539,
          19.875473022460938,
          18.609729766845703,
          19.971134185791016,
          17.466642379760742,
          17.942842483520508,
          20.738910675048828,
          21.67573356628418,
          21.63720703125
         ]
        }
       ],
       "layout": {
        "showlegend": true,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Dataset Projection"
        },
        "xaxis": {
         "scaleanchor": "y",
         "scaleratio": 1,
         "visible": false
        },
        "yaxis": {
         "scaleanchor": "x",
         "scaleratio": 1,
         "visible": false
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_embeds((projected_dataset_embeds, dataset_docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"animal activities\"\n",
    "results = collection.query(query_texts=[query], n_results=3, include=['embeddings', 'documents'])\n",
    "\n",
    "query_embeds = collection._embedding_function([query])[0]\n",
    "retreived_embeds, retreived_docs = results['embeddings'][0], results['documents'][0]\n",
    "projected_query_embeds = project_embeds([query_embeds], projection_transoform)\n",
    "projected_retreived_embeds = project_embeds(retreived_embeds, projection_transoform)\n",
    "\n",
    "plot_embeds(\n",
    "  (projected_dataset_embeds, dataset_docs),\n",
    "  (projected_query_embeds, query), \n",
    "  (projected_retreived_embeds, retreived_docs)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finally, let's build a RAG!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As of my last update in October 2023, Amazon's total revenue for the year 2023 was not yet available. Please check the latest financial reports or news sources for the most current information.\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "  model.invoke(\"What is amazon's total revenue in 2023? Answer in 1 line\").content\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_loader = PyPDFLoader(\n",
    "  \"./data/docs/2023-amazon-annual-letter.pdf\",\n",
    ")\n",
    "docs = doc_loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': './data/docs/2023-amazon-annual-letter.pdf', 'page': 1, 'page_label': '2'}, page_content='Dear Shareholders:\\nLast year at this time, I shared my enthusiasm and optimism for Amazon’s future. Today, I have even more.\\nThe reasons are many, but start with the progress we’ve made in our financial results and customer\\nexperiences, and extend to our continued innovation and the remarkable opportunities in front of us.\\nIn 2023, Amazon’s total revenue grew 12% year-over-year (“Y oY”) from $514B to $575B. By segment, North\\nAmerica revenue increased 12% Y oY from $316B to $353B, International revenue grew 11% Y oY from\\n$118B to $131B, and AWS revenue increased 13% Y oY from $80B to $91B.\\nFurther, Amazon’s operating income and Free Cash Flow (“FCF”) dramatically improved. Operating\\nincome in 2023 improved 201% Y oY from $12.2B (an operating margin of 2.4%) to $36.9B (an operating\\nmargin of 6.4%). Trailing Twelve Month FCF adjusted for equipment finance leases improved from -$12.8B\\nin 2022 to $35.5B (up $48.3B).')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the document into chunks with overlaps\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "doc_splits = text_splitter.split_documents(docs)\n",
    "doc_splits[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate embeddings using fastembed (or another model if preferred)\n",
    "text_embedding = TextEmbedding()\n",
    "embedding_values = list(text_embedding.embed([doc.page_content for doc in doc_splits]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = chromadb.Client()\n",
    "\n",
    "if \"rag\" in [collection.name for collection in client.list_collections()]:\n",
    "  client.delete_collection(\"rag\")\n",
    "\n",
    "collection = client.create_collection(\"rag\")\n",
    "collection.add(\n",
    "  documents=[doc.page_content for doc in doc_splits],\n",
    "  metadatas=[doc.metadata for doc in doc_splits],\n",
    "  ids=[str(i) for i in range(len(doc_splits))],\n",
    "  embeddings=embedding_values,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(\n",
    "  template=\"\"\"You are an assistant for question-answering tasks.\n",
    "    Use the following documents to answer the question.\n",
    "    If you don't know the answer, just say that you don't know.\n",
    "    Use three sentences maximum and keep the answer concise:\n",
    "    Question: {question}\n",
    "    Documents: {documents}\n",
    "    Answer:\n",
    "    \"\"\",\n",
    "  input_variables=[\"question\", \"documents\"],\n",
    ")\n",
    "\n",
    "rag_chain = prompt | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RAG:\n",
    "  def __init__(self, rag_chain, collection):\n",
    "    self.rag_chain = rag_chain\n",
    "    self.collection = collection\n",
    "\n",
    "  def print_retreived_docs(self, retreived_docs):\n",
    "    print(\"Retrieved documents:\")\n",
    "    for i in range(len(retreived_docs['ids'][0])):\n",
    "      print(f'Document: {i+1}')\n",
    "      print(f'Source: {retreived_docs[\"metadatas\"][0][i]}')\n",
    "      print(f'Data: {retreived_docs[\"documents\"][0][i]}\\n')\n",
    "    print('-' * 120 + '\\n')\n",
    "\n",
    "  def query(self, question, verbose=False):\n",
    "    ret = collection.query(query_texts=[question], n_results=4)\n",
    "    retreived_docs = ret['documents'][0]\n",
    "    if verbose: self.print_retreived_docs(ret)\n",
    "    response = rag_chain.invoke({\"question\": question, \"documents\": retreived_docs})\n",
    "    return response.content\n",
    "  \n",
    "rag = RAG(rag_chain, collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amazon's total revenue in 2023 is $575 billion, reflecting a 12% year-over-year growth from $514 billion in 2022. This growth includes increases in North America, International, and AWS revenue segments.\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "  rag.query(\"What is amazon's total revenue in 2023?\", verbose=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RAG - Refactored and simplify with langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As of my last update in October 2023, Amazon's total revenue for the year 2023 was approximately $514 billion.\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "  model.invoke(\"What is amazon's total revenue in 2023? Answer in 1 line\").content\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_loader = PyPDFLoader(\n",
    "  \"./data/docs/2023-amazon-annual-letter.pdf\",\n",
    ")\n",
    "docs = doc_loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "doc_splits = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = [str(i) for i in range(len(doc_splits))]\n",
    "vector_store = Chroma.from_documents(\n",
    "  doc_splits, \n",
    "  embedding=embeddings, \n",
    "  ids=ids,\n",
    "  collection_name=\"rag-chroma-1\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vector_store.as_retriever()\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "  template=\"\"\"You are an assistant for question-answering tasks.\n",
    "    Use the following documents to answer the question.\n",
    "    If you don't know the answer, just say that you don't know.\n",
    "    Use three sentences maximum and keep the answer concise:\n",
    "    Question: {question}\n",
    "    Documents: {documents}\n",
    "    Answer:\n",
    "    \"\"\",\n",
    "  input_variables=[\"question\", \"documents\"],\n",
    ")\n",
    "\n",
    "def format_docs(docs):\n",
    "  return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "rag_chain = (\n",
    "    {\"documents\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amazon's total sales in 2023 amounted to $574.785 billion. This represents a 12% increase compared to the previous year. The sales growth was driven by increased unit sales, advertising sales, and subscription services.\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "  rag_chain.invoke(\"What is amazon's total sales in 2023?\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_questions = [\n",
    "  'What were the primary drivers of revenue growth for Amazon in 2023?',\n",
    "  'What initiatives is Amazon undertaking to reduce its cost to serve in 2024?',\n",
    "  'What specific advancements did AWS make in 2023 regarding infrastructure, chip technology, and Generative AI?',\n",
    "  'According to Amazon\\'s CEO, what defining characteristics exemplify the company\\'s culture and approach to innovation?',\n",
    "  'How does Amazon empower its employees to act like \"builders\"?',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q:  What specific advancements did AWS make in 2023 regarding infrastructure, chip technology, and Generative AI?\n",
      "A:  In 2023, AWS introduced the Graviton4 CPU chips, offering up to 30% better compute performance and 75% more memory bandwidth compared to Graviton3. They also launched AWS Trainium2 chips, which provide up to four times faster machine learning training for generative AI applications. Additionally, AWS expanded its infrastructure to include 105 Availability Zones across 33 geographic regions, with six new regions planned.\n"
     ]
    }
   ],
   "source": [
    "q = eval_questions[2]\n",
    "print(\"Q: \", q)\n",
    "print(\"A: \", rag_chain.invoke(q))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evalutaion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Evaluation](./data/slides/slide5.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
